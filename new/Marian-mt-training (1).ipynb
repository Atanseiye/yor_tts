{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0980a322-6ac9-4672-bc16-6d4a326b6e2c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.10->transformers[torch]) (12.3.52)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: meteor in /opt/conda/lib/python3.10/site-packages (0.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-firestore in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Collecting google-cloud-firestore\n",
      "  Obtaining dependency information for google-cloud-firestore from https://files.pythonhosted.org/packages/36/3c/ff2a16dc5b56afdbf41993f7b1d3e1d227f0fe030eb57675a4f38cf83298/google_cloud_firestore-2.13.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_firestore-2.13.1-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore) (2.3.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (2.23.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (1.58.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-firestore) (0.5.0)\n",
      "Downloading google_cloud_firestore-2.13.1-py2.py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.5/289.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: google-cloud-firestore\n",
      "  Attempting uninstall: google-cloud-firestore\n",
      "    Found existing installation: google-cloud-firestore 2.13.0\n",
      "    Uninstalling google-cloud-firestore-2.13.0:\n",
      "      Successfully uninstalled google-cloud-firestore-2.13.0\n",
      "Successfully installed google-cloud-firestore-2.13.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: firebase_admin in /opt/conda/lib/python3.10/site-packages (6.2.0)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (0.13.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (1.8.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (2.11.0)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (2.8.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.22.1 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.9.1 in /opt/conda/lib/python3.10/site-packages (from firebase_admin) (2.13.1)\n",
      "Requirement already satisfied: requests>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from cachecontrol>=0.12.6->firebase_admin) (2.31.0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from cachecontrol>=0.12.6->firebase_admin) (1.0.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (3.20.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (1.58.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (1.48.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.1.1)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->firebase_admin) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.7.8->firebase_admin) (3.0.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore>=2.9.1->firebase_admin) (2.3.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-firestore>=2.9.1->firebase_admin) (1.22.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage>=1.37.1->firebase_admin) (2.6.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin) (1.15.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media>=2.6.0->google-cloud-storage>=1.37.1->firebase_admin) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client>=1.7.8->firebase_admin) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase_admin) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase_admin) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase_admin) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase_admin) (2023.7.22)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin) (0.5.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.34.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-auth (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install rouge_score\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n",
    "!pip install accelerate>=0.20.1\n",
    "!pip install meteor\n",
    "!pip install --upgrade google-cloud-firestore\n",
    "!pip install firebase_admin\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321f77bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d88aa-775a-4937-b17d-ccf5a9fad936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c83ea-4aa1-49fa-b501-08a92030d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d509a34f-a6e8-4b5c-87e2-3853efe954b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from google.cloud import firestore\n",
    "from transformers import MarianTokenizer\n",
    "import nltk.translate.meteor_score as meteor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (AutoModel, MarianMTModel, MarianTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, PreTrainedTokenizerBase, PreTrainedModel, T5ForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53eff64-3403-4a11-9c35-0ca768d6917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d680cacd-4cff-4e64-9ffa-e643130cf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod 777 /home/mac/.config/gcloud/application_default_credentials.json\n",
    "#!sudo chmod 777 /home/mac/marian-MT/yoruba_tokenizer/tokenizer_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11de3c2-1ef5-493d-b50b-059cc443483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Firestore\n",
    "db = firestore.Client()\n",
    "\n",
    "# Firestore collection name\n",
    "collection_name = 'text_data'  # Replace with your collection name\n",
    "\n",
    "# Reference to the Firestore collection\n",
    "collection_ref = db.collection(collection_name)\n",
    "\n",
    "# Query Firestore to get all documents\n",
    "documents = collection_ref.stream()\n",
    "data = []\n",
    "# Iterate over the documents and retrieve data\n",
    "for document in documents:\n",
    "    document_data = document.to_dict()\n",
    "    data.append(document_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7797a9f0-2f7c-4123-96d1-2f106abd9698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f4f336-268c-43cd-8001-d7ae11d00c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"df = pd.DataFrame(data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b7f46c-7e41-49c3-93b0-1aeca756dc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given all that, here are some questions you ca...</td>\n",
       "      <td>Pẹ̀lú gbogbo ìwọ̀nyí, ìwọ̀nyí ni ìbéèrè tí o l...</td>\n",
       "      <td>36308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Then God said: Let the earth bring forth livin...</td>\n",
       "      <td>Lẹ́yìn náà, Ọlọ́run wá sọ pé: Kí ilẹ̀ mú àwọn ...</td>\n",
       "      <td>21439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You can say some of this is education.</td>\n",
       "      <td>Ẹ lè sọ wí pé díẹ̀ nínú àwọn yìí jẹ́ ètò-ẹ̀kọ́.</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My whole being will rejoice in my God.</td>\n",
       "      <td>Gbogbo ara mi máa yọ̀ nínú Ọlọ́run mi.</td>\n",
       "      <td>19428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You heard that it was said to those of ancient...</td>\n",
       "      <td>Ẹ gbọ́ pé a sọ fún àwọn èèyàn àtijọ́ pé: O ò g...</td>\n",
       "      <td>31445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0  Given all that, here are some questions you ca...   \n",
       "1  Then God said: Let the earth bring forth livin...   \n",
       "2             You can say some of this is education.   \n",
       "3             My whole being will rejoice in my God.   \n",
       "4  You heard that it was said to those of ancient...   \n",
       "\n",
       "                                              Yoruba     ID  \n",
       "0  Pẹ̀lú gbogbo ìwọ̀nyí, ìwọ̀nyí ni ìbéèrè tí o l...  36308  \n",
       "1  Lẹ́yìn náà, Ọlọ́run wá sọ pé: Kí ilẹ̀ mú àwọn ...  21439  \n",
       "2    Ẹ lè sọ wí pé díẹ̀ nínú àwọn yìí jẹ́ ètò-ẹ̀kọ́.   1159  \n",
       "3             Gbogbo ara mi máa yọ̀ nínú Ọlọ́run mi.  19428  \n",
       "4  Ẹ gbọ́ pé a sọ fún àwọn èèyàn àtijọ́ pé: O ò g...  31445  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81f6238-8c08-471e-bd5e-b69ee1faaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df.to_parquet('MT-data.parquet')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e88471-ca94-464c-a4c9-4f810e72304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"MT-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e181cd-c031-49c1-889e-f66669a58d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the columns are named 'English', 'Yoruba', and 'ID'\n",
    "english_texts = df['English'].tolist()\n",
    "yoruba_texts = df['Yoruba'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0ce554-fbe2-41c2-bec0-6f1433efe621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained SentencePiece model\n",
    "model_name = \"Helsinki-NLP/opus-mt-yo-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load pre-trained model to extract embeddings\n",
    "source_embedder = AutoModel.from_pretrained('bert-base-uncased')\n",
    "target_embedder = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "486030dd-30ae-4bfb-9a75-e84b13710c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoruba_tokenized = tokenizer(yoruba_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "english_tokenized = tokenizer(english_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccec67a-3666-44b9-a975-f88b02543256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-yo-en', vocab_size=56836, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t56835: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7b87322-0aa8-46eb-b3b9-95eebe107127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and evaluation sets\n",
    "yoruba_train, yoruba_eval, english_train, english_eval = train_test_split(yoruba_texts, english_texts, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2d1491b-8243-4c2b-9abc-9b8609a488d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://tokenizer/vocab.json [Content-Type=application/json]...\n",
      "Copying file://tokenizer/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://tokenizer/target.spm [Content-Type=application/octet-stream]...  \n",
      "Copying file://tokenizer/special_tokens_map.json [Content-Type=application/json]...\n",
      "- [4 files][  2.2 MiB/  2.2 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://tokenizer/source.spm [Content-Type=application/octet-stream]...\n",
      "- [5 files][  3.0 MiB/  3.0 MiB]                                                \n",
      "Operation completed over 5 objects/3.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r tokenizer gs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1220d053-9d9f-4713-b7f6-f00ebbc24440",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.11.0)\n",
      "Collecting google-cloud-storage\n",
      "  Obtaining dependency information for google-cloud-storage from https://files.pythonhosted.org/packages/04/72/71b1b531cefa1daff8f6a2a70b4d4fa18dd4da851b5486d53578811b0838/google_cloud_storage-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_storage-2.13.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting google-auth<3.0dev,>=2.23.3 (from google-cloud-storage)\n",
      "  Obtaining dependency information for google-auth<3.0dev,>=2.23.3 from https://files.pythonhosted.org/packages/86/a7/75911c13a242735d5aeaca6a272da380335ff4ba5f26d6b2ae20ff682d13/google_auth-2.23.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.5.0)\n",
      "Downloading google_cloud_storage-2.13.0-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-auth, google-cloud-storage\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.23.0\n",
      "    Uninstalling google-auth-2.23.0:\n",
      "      Successfully uninstalled google-auth-2.23.0\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '_metadata.cpython-310.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2fcfdb-e651-400b-a1f4-758c21f3b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoruba_tokenized = tokenizer(yoruba_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51619bee-5fff-4b88-9376-7d4b852a2233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'gs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yoruba_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMarianTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1940\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files:\n\u001b[1;32m   1938\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 1940\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be a string, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(repo_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'gs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "yoruba_tokenizer = MarianTokenizer.from_pretrained(\"gs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f07f14f-01f0-405a-be64-237d24655112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianTokenizer(name_or_path='gs://nkenne-machinelearning-bucket/marian-MT/yoruba_tokenizer', vocab_size=56836, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t56835: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoruba_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7eaaa509-cba6-4b0b-9d72-af9eaac53b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoruba_tokenized = yoruba_tokenizer(yoruba_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "english_tokenized = yoruba_tokenizer(english_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a51a7dd-9d14-4312-93b8-db8582477fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_texts, target_texts, source_tokenizer, target_tokenizer, source_embedder, target_embedder):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.source_tokenizer = source_tokenizer\n",
    "        self.target_tokenizer = target_tokenizer\n",
    "        self.target_embedder = target_embedder\n",
    "        self.source_embedder = source_embedder \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.source_texts[idx]\n",
    "        target_text = self.target_texts[idx]\n",
    "\n",
    "        source_inputs = self.source_tokenizer(source_text, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True)\n",
    "        target_inputs = self.target_tokenizer(target_text, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True)\n",
    "\n",
    "        # Extract embeddings for the source and target text using the respective embedder\n",
    "        # You can use a pre-trained transformer model or any other method here\n",
    "        source_embeddings = self.source_embedder(source_tokens[\"input_ids\"]).last_hidden_state.squeeze(0)\n",
    "        target_embeddings = self.target_embedder(target_tokens[\"input_ids\"]).last_hidden_state.squeeze(0)\n",
    "\n",
    "\n",
    "        # return {\n",
    "        #     \"input_ids\": source_inputs[\"input_ids\"].flatten(),\n",
    "        #     \"attention_mask\": source_inputs[\"attention_mask\"].flatten(),\n",
    "        #     \"labels\": target_inputs[\"input_ids\"].flatten(),\n",
    "        # }\n",
    "\n",
    "        return {\n",
    "            \"source_embeddings\": source_embeddings,  # Embeddings for the source language\n",
    "            \"target_embeddings\": target_embeddings,  # Embeddings for the target language\n",
    "            \"labels\": target_tokens[\"input_ids\"].squeeze(0),  # Target tokens as labels\n",
    "        }\n",
    "\n",
    "translation_dataset = TranslationDataset(yoruba_train, english_train, yoruba_tokenized, english_tokenized, source_embedder, target_embedder)\n",
    "evaluation_dataset = TranslationDataset(yoruba_eval, english_eval, yoruba_tokenized, english_tokenized, source_embedder, target_embedder)\n",
    "data_loader = DataLoader(translation_dataset, batch_size=4, shuffle=True)\n",
    "eval_data_loader = DataLoader(evaluation_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c938cc7-f09f-446e-b03e-f86e16ecf8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NEW\n",
    "'''\n",
    "class CustomT5ForConditionalGeneration(T5ForConditionalGeneration):\n",
    "    def forward(self, input_ids=None, attention_mask=None, decoder_input_ids=None, labels=None, encoder_outputs=None, **kwargs):\n",
    "        if input_ids is None:\n",
    "            # Use precomputed embeddings instead of token IDs\n",
    "            encoder_outputs = self.encoder(inputs_embeds=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        else:\n",
    "            # Fallback to normal behavior if input_ids are provided\n",
    "            encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        \n",
    "        # Decoder logic remains unchanged\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            encoder_hidden_states=encoder_outputs[0],\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        return decoder_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e47288db-b006-4c92-9b9d-da192fd2a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "model_2 =  CustomT5ForConditionalGeneration.from_pretrained('t5-small') '''Modified''' # 't5-base' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07db2d51-3ddc-4c85-b791-93126624ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCS bucket and local directory\n",
    "bucket_name = \"nkenne-machinelearning-bucket\"\n",
    "local_model_directory = \"model\"  # Replace with your local directory path\n",
    "gcs_path = \"marian-MT/model\"  # Replace with your GCS bucket path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dac5059c-29d7-40a1-8598-03a124771fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified\n",
    "'''\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    per_device_train_batch_size=8,  # Set this to a larger value\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    output_dir=\"model\",\n",
    "    num_train_epochs=1,  # Increase if needed\n",
    "    save_steps=400,\n",
    "    weight_decay=0.01,  # For reqularization\n",
    "    eval_steps=400,\n",
    "    save_steps=500\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-5,  # Experiment with learning rate schedule\n",
    "    overwrite_output_dir=True,\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "067d33fb-beb7-48cb-9c80-89fd5b58b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from google.cloud import storage\n",
    "\n",
    "def sync_to_gcs(local_directory, gcs_path):\n",
    "    storage_client = storage.Client()\n",
    "    bucket_name = \"nkenne-machinelearning-bucket\"\n",
    "\n",
    "    while True:\n",
    "        time.sleep(300)  # Adjust the time interval for synchronization as needed (e.g., sync every 5 minutes)\n",
    "\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(gcs_path)\n",
    "\n",
    "        # Copy contents of local directory to GCS\n",
    "        blob.upload_from_filename(local_directory, if_generation_match=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a07d41f0-b09c-43f6-a292-dc24e68d447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified\n",
    "'''\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=english_tokenized,\n",
    "    model=model_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c49735da-2563-4de8-84a8-a7e8cff16d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53317</th>\n",
       "      <td>They were singing the song of Moses the slave ...</td>\n",
       "      <td>Wọ́n ń kọ orin Mósè ẹrú Ọlọ́run àti orin Ọ̀dọ́...</td>\n",
       "      <td>25454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53318</th>\n",
       "      <td>I graduated high school in Cleveland, Ohio, 1975.</td>\n",
       "      <td>Mo kẹ́kọ̀ọ́ jáde ní ilé-ẹ̀kọ́ mẹ́wàá Cleveland...</td>\n",
       "      <td>41099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53319</th>\n",
       "      <td>It is simply a euphemism for theft to say àfọw...</td>\n",
       "      <td>Àdàpè olè ní ń jẹ́ àfọwọ́rá.</td>\n",
       "      <td>40469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53320</th>\n",
       "      <td>And apart from that, she's not just a Nigerian.</td>\n",
       "      <td>Yàtọ̀ sí èyí, kì í ṣe ọmọ orílẹ̀-èdè Nàìjíríà ...</td>\n",
       "      <td>37029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53321</th>\n",
       "      <td>Frankly speaking.</td>\n",
       "      <td>Ní òtítọ́ sísọ.</td>\n",
       "      <td>8960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "53317  They were singing the song of Moses the slave ...   \n",
       "53318  I graduated high school in Cleveland, Ohio, 1975.   \n",
       "53319  It is simply a euphemism for theft to say àfọw...   \n",
       "53320    And apart from that, she's not just a Nigerian.   \n",
       "53321                                  Frankly speaking.   \n",
       "\n",
       "                                                  Yoruba     ID  \n",
       "53317  Wọ́n ń kọ orin Mósè ẹrú Ọlọ́run àti orin Ọ̀dọ́...  25454  \n",
       "53318  Mo kẹ́kọ̀ọ́ jáde ní ilé-ẹ̀kọ́ mẹ́wàá Cleveland...  41099  \n",
       "53319                       Àdàpè olè ní ń jẹ́ àfọwọ́rá.  40469  \n",
       "53320  Yàtọ̀ sí èyí, kì í ṣe ọmọ orílẹ̀-èdè Nàìjíríà ...  37029  \n",
       "53321                                Ní òtítọ́ sísọ.   8960  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66a36d40-f630-4bab-a154-6766ee966e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(56836, 512, padding_idx=56835)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(56836, 512, padding_idx=56835)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(56836, 512, padding_idx=56835)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=56836, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "926c5c50-3dab-468a-81f9-b30218b312d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb58a630-3688-43c8-b22d-354e1cb041c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='1499' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  40/1499 01:45 < 1:07:45, 0.36 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#compute_metrics=compute_metrics,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1897\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_2,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    train_dataset=translation_dataset,\n",
    "    eval_dataset=evaluation_dataset,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de62fc-992a-482c-b937-aee3a819252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NEW\n",
    "'''\n",
    "\n",
    "hypotheses = []\n",
    "\n",
    "# Iterate over the test data\n",
    "for line in test_data_yor:\n",
    "    # Tokenize the Yoruba sentence and convert it to embeddings\n",
    "    embeddings = yoruba_tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)[\"input_ids\"].to(device)\n",
    "    \n",
    "    # Forward pass through the model using embeddings instead of token IDs. Assuming the model has been modified to accept embeddings\n",
    "    encoder_outputs = checkpoint_model.encoder(inputs_embeds=embeddings)  # Use the encoder with embeddings\n",
    "    \n",
    "    # Generate translations by decoding the output embeddings from the decoder\n",
    "    # You may want to use the decoder with its own logic for generation\n",
    "    translated_embeddings = checkpoint_model.decoder.generate(\n",
    "        encoder_outputs=encoder_outputs[0],  # This is the encoded embeddings from the encoder\n",
    "        max_length=512  # You can set your max length for generation\n",
    "    )\n",
    "    \n",
    "    # Decode the translated embeddings into tokens and then into text\n",
    "    translated_text = english_tokenizer.decode(translated_embeddings[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Append the translated text to hypotheses\n",
    "    hypotheses.append(translated_text)\n",
    "\n",
    "\n",
    "# Calculate the METEOR score\n",
    "meteor_scores = []\n",
    "for i in range(len(hypotheses)):\n",
    "    # Tokenize the reference and hypothesis\n",
    "    reference_tokens = references[i].split()\n",
    "    hypothesis_tokens = hypotheses[i].split()\n",
    "\n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.meteor_score([reference_tokens], hypothesis_tokens)\n",
    "    meteor_scores.append(meteor_score)\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(hypotheses)):\n",
    "    print(\"Input sentence:\", test_data_yor[i])\n",
    "    print(\"Predicted translation:\", hypotheses[i])\n",
    "    print(\"Actual translation:\", references[i])\n",
    "    print(f\"METEOR score: {meteor_scores[i]:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a88a701-1d91-4026-926d-366885f46e85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Ó sése kí n rin  ìrìn àjò lọ sí ibi tó farasin ní oṣù January.\n",
      "\n",
      "Predicted translation: <pad> He started me to travel to the place that was in the month of January.</s>\n",
      "Actual translation: I might travel out to a quiet place in the month of January. .\n",
      "\n",
      "METEOR score: 0.4470\n",
      "\n",
      "Input sentence: Mo fẹ́ràn láti rẹjú ní wàrawàra lẹ̀yìn oúnjẹ ò̩sán lojojúmọ́.\n",
      "\n",
      "Predicted translation: <pad> I love to be carried before the evening of the night.</s>\n",
      "Actual translation: I like to take a nap immediately after lunch everyday.\n",
      "\n",
      "METEOR score: 0.0980\n",
      "\n",
      "Input sentence: Mo kórìíra láti máa lo sí àpèjẹ pèlú àwọn ọ̀rẹ́ mi ṣùgbọ́n mo fẹ́ràn láti máa wo tẹlifíṣọ̀n\n",
      "\n",
      "Predicted translation: <pad> I hate to use my friends with my friends but I love to look at movies</s>\n",
      "Actual translation: I  don’t like going out to parties with friends but I like watching TV..\n",
      "\n",
      "METEOR score: 0.3574\n",
      "\n",
      "Input sentence: Ẹ̀rù bà mí nígbà tí mo rí fọ́tò ẹnì kan tó wọ aṣọ ológun ní ọ̀dẹ̀dẹ̀ ilé náà.\n",
      "\n",
      "Predicted translation: <pad> I was afraid when I saw someone who clotheed the military garment at the house.</s>\n",
      "Actual translation: To my horror, I noticed that there was a photograph of someone in a military uniform in the hallway.\n",
      "\n",
      "METEOR score: 0.1337\n",
      "\n",
      "Input sentence: À ń gbìn, a sì ń bomi rin, àmọ́ Ọlọ́run ló ń mú kó dàgbà\n",
      "\n",
      "Predicted translation: <pad> We plant and drink, but it is God who makes it old.</s>\n",
      "Actual translation: We plant and water, but God makes it grow.\n",
      "\n",
      "METEOR score: 0.6752\n",
      "\n",
      "Input sentence: Ńṣe làwọn aboyún tó ń mu sìgá ń fẹ̀mí oyún inú wọn wewu.\n",
      "\n",
      "Predicted translation: <pad> The young women who use to drink disgrace their children.</s>\n",
      "Actual translation: Pregnant women who smoke endanger their unborn babies.\n",
      "\n",
      "METEOR score: 0.3079\n",
      "\n",
      "Input sentence: Ọ̀pọ̀ jù lọ lára wa ni kò lè hùmọ̀ iṣẹ́ ẹ̀rọ àkọ̀tun èyíkéyìí.\n",
      "\n",
      "Predicted translation: <pad> Most of us cannot take any same work.</s>\n",
      "Actual translation: Most of us can probably do little to develop some innovative new technology.\n",
      "\n",
      "METEOR score: 0.2337\n",
      "\n",
      "Input sentence: Ó máa ń han-anrun gan-an látìgbàdégbà lóru, ìgbà míì sì rèé, ó lè ta jí wùyà lójú oorun tí yóò sì máa mi hẹlẹhẹlẹ.\n",
      "\n",
      "Predicted translation: <pad> He is very very very very very much from night, and sometimes he can start in sleep and sleep.</s>\n",
      "Actual translation: He snored loudly and irregularly every night and at times violently jerked himself awake, gasping for breath.\n",
      "\n",
      "METEOR score: 0.0867\n",
      "\n",
      "Input sentence: Láàárọ̀ ọjọ́ kejì, àwọn tọkọtaya náà pinnu láti tètè jí kúrò níbi tí wọ́n dé sí kí wọ́n lè lọ wàásù ní àgbègbè míì.\n",
      "\n",
      "Predicted translation: <pad> The next month, the brothers decided to go up quickly from their place to preach in another region.</s>\n",
      "Actual translation: The next morning, the couple decided to leave very early to visit another area.\n",
      "\n",
      "METEOR score: 0.3948\n",
      "\n",
      "Input sentence: Ìdí nìyẹn tí ìwọ kò tíì fi ṣàìsàn.\n",
      "\n",
      "Predicted translation: <pad> That is why you have not been sicked.</s>\n",
      "Actual translation: That is why you have not grown sick.\n",
      "\n",
      "METEOR score: 0.7390\n",
      "\n",
      "Input sentence: Nínú Yàrá Kan Lórí Òkè Pẹ̀tẹ́ẹ̀sì.\n",
      "\n",
      "Predicted translation: <pad> In a Lagos on Britain.</s>\n",
      "Actual translation: In an Upstairs Room.\n",
      "\n",
      "METEOR score: 0.1190\n",
      "\n",
      "Input sentence: Àṣírí Kan Tó O Lè Sọ fún Ẹlòmíì.\n",
      "\n",
      "Predicted translation: <pad> One Secret You can Tell another.</s>\n",
      "Actual translation: A Secret You Can Tell Others.\n",
      "\n",
      "METEOR score: 0.6506\n",
      "\n",
      "Input sentence: Ẹ Mú Ìsọ̀rọ̀ Ẹni Lẹ́yìn Kúrò.\n",
      "\n",
      "Predicted translation: <pad> Speak Up One's Speech.</s>\n",
      "Actual translation: Put Away Backbiting.\n",
      "\n",
      "METEOR score: 0.0000\n",
      "\n",
      "Input sentence: Bí àpẹẹrẹ, jàǹbá, àìsàn tàbí ọjọ́ ogbó ti sọ àwọn míì di aláìlera.\n",
      "\n",
      "Predicted translation: <pad> For example, others have been injured by damage, disease, or old age.</s>\n",
      "Actual translation: Some are challenged physically because of injury, disease, or aging.\n",
      "\n",
      "METEOR score: 0.1820\n",
      "\n",
      "Input sentence: Irú èèyàn tí wọ́n sọ pé ó jẹ́ ni ẹni tó “ń lépa ipò ọlá lójú méjèèjì, tó jọra ẹ̀ lójú bí nǹkan míì, tó sì jẹ́ ògbóǹtagí nínú ọ̀ràn ìṣèlú.\n",
      "\n",
      "Predicted translation: <pad> It is the kind of people that they say is the one who pursues honor, who is disgraced as another thing and is a <unk> ical <unk>.</s>\n",
      "Actual translation: He has been described as a man “of consummate ambition, prodigious arrogance, and unsurpassed political skill.\n",
      "\n",
      "METEOR score: 0.0872\n",
      "\n",
      "Input sentence: Bí ẹnì kan bá jí èèyàn gbé tó sì tà á, ńṣe ni wọ́n máa pa ajínigbé náà.\n",
      "\n",
      "Predicted translation: <pad> If someone starts a man and sells it, the person will be killed.</s>\n",
      "Actual translation: Kidnapping a man and then selling him was punishable by death.\n",
      "\n",
      "METEOR score: 0.3319\n",
      "\n",
      "Input sentence: Ó fẹ́rẹ̀ẹ́ jẹ́ pé nínú gbogbo àwùjọ ẹ̀dá ni wọ́n ti mọ àwọn àǹfààní tó wà nínú wíwọ́ ara.\n",
      "\n",
      "Predicted translation: <pad> Almost only all creators have been known the benefities of the body.</s>\n",
      "Actual translation: The benefits of massage have long been recognized in almost all cultures.\n",
      "\n",
      "METEOR score: 0.2479\n",
      "\n",
      "Input sentence: Òjòwú pọ́ńbélé sì ni.\n",
      "\n",
      "Predicted translation: <pad> And it is very very very much.</s>\n",
      "Actual translation: He’s intensely jealous.\n",
      "\n",
      "METEOR score: 0.0000\n",
      "\n",
      "Input sentence: Gẹ́gẹ́ bí ìṣe rẹ̀, ó ti to tábìlì fún èèyàn méjì.\n",
      "\n",
      "Predicted translation: <pad> As his service, he has set the table for two people.</s>\n",
      "Actual translation: Out of habit, she has set the table for two.\n",
      "\n",
      "METEOR score: 0.4882\n",
      "\n",
      "Input sentence: Àwùjọ àwọn èwe kan tí kò tíì pé ọmọ ọdún mẹ́tàlá jọ ń gbá bọ́ọ̀lù aláfọwọ́gbá tó wà fún ọkùnrin àtobìnrin.\n",
      "\n",
      "Predicted translation: <pad> A group of young children who were 13 years old was coming together with men and women.</s>\n",
      "Actual translation: A group of preteens are playing a game of coed football.\n",
      "\n",
      "METEOR score: 0.1282\n",
      "\n",
      "Input sentence: Nígbà tó yá, ó bí arẹwà ọmọbìnrin kan.\n",
      "Predicted translation: <pad> In time, he gave birth to a beautiful daughter.</s>\n",
      "Actual translation: In time, she gave birth to a beautiful baby girl.\n",
      "METEOR score: 0.6918\n",
      "\n",
      "Overall METEOR score: 0.3048\n"
     ]
    }
   ],
   "source": [
    "# Read your Yoruba test data\n",
    "with open(\"small_vocab_yor\", \"r\") as f:\n",
    "    test_data_yor = f.readlines()\n",
    "\n",
    "# Translate the Yoruba sentences and store them as hypotheses\n",
    "hypotheses = []\n",
    "for line in test_data_yor:\n",
    "    input_ids = yoruba_tokenizer(line, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    translated_text = checkpoint_model.generate(input_ids)[0]\n",
    "    translated_text = english_tokenizer.decode(translated_text)\n",
    "    hypotheses.append(translated_text)\n",
    "\n",
    "# Read the English references\n",
    "with open(\"small_vocab_en\", \"r\") as f:\n",
    "    references = f.readlines()\n",
    "\n",
    "# Calculate the METEOR score\n",
    "meteor_scores = []\n",
    "for i in range(len(hypotheses)):\n",
    "    # Tokenize the reference and hypothesis\n",
    "    reference_tokens = references[i].split()\n",
    "    hypothesis_tokens = hypotheses[i].split()\n",
    "\n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.meteor_score([reference_tokens], hypothesis_tokens)\n",
    "    meteor_scores.append(meteor_score)\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(hypotheses)):\n",
    "    print(\"Input sentence:\", test_data_yor[i])\n",
    "    print(\"Predicted translation:\", hypotheses[i])\n",
    "    print(\"Actual translation:\", references[i])\n",
    "    print(f\"METEOR score: {meteor_scores[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Calculate the overall METEOR score\n",
    "overall_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(f\"Overall METEOR score: {overall_meteor_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08342b61-58e2-4c93-b167-e3a028111dff",
   "metadata": {},
   "source": [
    "TRAIN FROM CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca7a9653-e5ef-4e46-a667-b66195f66cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained SentencePiece model\n",
    "model_name = \"Helsinki-NLP/opus-mt-yo-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b0ff6ee-58fb-49b8-8cee-be60f421e6f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ped62in7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='47246.312 MB of 47246.312 MB uploaded (0.324 MB deduped)\\r'), FloatProgress(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▃▄▅▆▇▇▇▇██▇██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▄▄▆▄▄▃▃▄▃▄▃▂▂▂▅▅▂▄▁▂▂▁▁▁▁▁▅▃▃▂▂▁▃▃▄▅▂▂█</td></tr><tr><td>eval/samples_per_second</td><td>▃▅▅▃▅▅▆▆▅▆▅▆▇▇▇▄▄▇▅█▇▇█████▄▆▆▇▇█▆▆▅▄▇▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▃▅▅▃▅▅▆▆▅▆▅▆▇▇▇▄▄▇▅█▇▇█████▄▆▆▇▇█▆▆▅▄▇▇▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▁▂▁▁▂▂▁▂▁▂▂▂▂▂▃▃▃▄▄▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇█▇</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.17589</td></tr><tr><td>eval/runtime</td><td>25.4237</td></tr><tr><td>eval/samples_per_second</td><td>209.765</td></tr><tr><td>eval/steps_per_second</td><td>26.235</td></tr><tr><td>train/epoch</td><td>14.99</td></tr><tr><td>train/global_step</td><td>22485</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4571</td></tr><tr><td>train/total_flos</td><td>1.2659487655919616e+16</td></tr><tr><td>train/train_loss</td><td>0.37268</td></tr><tr><td>train/train_runtime</td><td>11564.6727</td></tr><tr><td>train/train_samples_per_second</td><td>62.244</td></tr><tr><td>train/train_steps_per_second</td><td>1.944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-dream-13</strong> at: <a href='https://wandb.ai/kingalagbe/Yor-En-MachineTranslation/runs/ped62in7' target=\"_blank\">https://wandb.ai/kingalagbe/Yor-En-MachineTranslation/runs/ped62in7</a><br/>Synced 6 W&B file(s), 0 media file(s), 452 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231114_134549-ped62in7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ped62in7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef1e794370342d2ab48815c02edf4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113407222243648, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20231114_172307-f3qzvnoj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kingalagbe/Yor-En-MachineTranslation/runs/f3qzvnoj' target=\"_blank\">earthy-oath-14</a></strong> to <a href='https://wandb.ai/kingalagbe/Yor-En-MachineTranslation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kingalagbe/Yor-En-MachineTranslation' target=\"_blank\">https://wandb.ai/kingalagbe/Yor-En-MachineTranslation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kingalagbe/Yor-En-MachineTranslation/runs/f3qzvnoj' target=\"_blank\">https://wandb.ai/kingalagbe/Yor-En-MachineTranslation/runs/f3qzvnoj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4801' max='22485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4801/22485 41:32 < 2:33:04, 1.93 it/s, Epoch 3.20/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>1.210559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>1.222804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>1.229103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>1.236547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>1.240833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>1.245431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>1.245172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>1.246650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>1.249716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>1.249992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>1.252706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>1.256656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-400)... Done. 7.2s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpibdz2sw4, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpiqpfkjzx, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmprxh6vtjb, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmplvy034hn, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpb2_3a8iq, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp_kdd4w9i, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmps8g93eb0, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpqqnkz97b, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-800)... Done. 7.5s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpxyx_ec7k, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmptr2u6qua, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpv_f42l_a, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpsm_lytxk, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpco5ji2a2, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-1200)... Done. 7.7s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmprn58xnao, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpzpa7j_mi, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp38k05a8b, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpqiw8rf38, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpemi8muig, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-1600)... Done. 7.5s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpbqd2fz17, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp5l62yuuj, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpas3pik0e, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmptdq819_w, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp1jc94_w7, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-2000)... Done. 7.8s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpfieb_fog, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp9mo6u25v, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmptqeowfdh, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpqa3ch0xb, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpnypop17l, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-2400)... Done. 7.5s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpxg9elhzn, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpe6842fau, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpypdfyzhh, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpkheado7a, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp357359t4, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-2800)... Done. 7.6s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpajgnjuyt, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmppy97bucc, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp1p31_cqr, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpj70vj_jl, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp436j7_3o, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-3200)... Done. 7.4s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpo3p1mspp, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp9dmlt2ue, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpk7g8qx67, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpn6vutqgj, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpahlbtgye, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-3600)... Done. 7.6s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmprp766sh9, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp_hbi192m, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp_6k59094, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpwq80102b, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmps671b2hc, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-4000)... Done. 7.8s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpyfwla8y3, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmph0a51512, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpfsdrf29i, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp90081p1w, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp44gzlce0, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-4400)... Done. 7.7s\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpf38cstnw, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmptmbxte6b, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp50t8vljf, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmpothajkk7, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "wandb: WARNING Failed to cache /home/jupyter/.local/share/wandb/artifacts/staging/tmp7zo7q57v, ignoring [Errno 2] No such file or directory: '/home/jupyter/.cache/wandb/artifacts'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model/checkpoint-4800)... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 92\u001b[0m\n\u001b[1;32m     83\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     84\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     85\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1984\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1984\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2340\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m-> 2340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_save\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_callback.py:395\u001b[0m, in \u001b[0;36mCallbackHandler.on_save\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_save\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    394\u001b[0m     control\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_save\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_callback.py:406\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 406\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:828\u001b[0m, in \u001b[0;36mWandbCallback.on_save\u001b[0;34m(self, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m checkpoint_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (args\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;241m==\u001b[39m args\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    826\u001b[0m )\n\u001b[1;32m    827\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39mcheckpoint_name, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mcheckpoint_metadata)\n\u001b[0;32m--> 828\u001b[0m \u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mlog_artifact(artifact, aliases\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/artifacts/artifact.py:1246\u001b[0m, in \u001b[0;36mArtifact.add_dir\u001b[0;34m(self, local_path, name)\u001b[0m\n\u001b[1;32m   1244\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m   1245\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39mPool(num_threads)\n\u001b[0;32m-> 1246\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_manifest_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1247\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1248\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"Yor-En-MachineTranslation\", job_type=\"train\", settings=wandb.Settings(start_method=\"fork\"))\n",
    "# Set the WANDB_STORAGE environment variable to your GCS bucket URL\n",
    "!export WANDB_STORAGE=\"gs://nkenne-machinelearning-bucket/marian-MT/model\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"checkpoint\"\n",
    "\n",
    "def batch_encode(texts, tokenizer, max_length=512):\n",
    "    encoded_texts = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = encoded_texts[\"input_ids\"].flatten()\n",
    "    attention_mask = encoded_texts[\"attention_mask\"].flatten()\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_texts, target_texts, tokenizer, max_length=512):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.source_texts[idx]\n",
    "        target_text = self.target_texts[idx]\n",
    "\n",
    "        encoded_sources = batch_encode([source_text], self.tokenizer, self.max_length)\n",
    "        encoded_targets = batch_encode([target_text], self.tokenizer, self.max_length)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoded_sources[\"input_ids\"],\n",
    "            \"attention_mask\": encoded_sources[\"attention_mask\"],\n",
    "            \"labels\": encoded_targets[\"input_ids\"],\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_parquet(\"MT-data.parquet\")\n",
    "    english_texts = df['English'].tolist()\n",
    "    yoruba_texts = df['Yoruba'].tolist()\n",
    "\n",
    "    # Split data into training and evaluation sets\n",
    "    yoruba_train, yoruba_eval, english_train, english_eval = train_test_split(yoruba_texts, english_texts, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Prepare training and evaluation datasets\n",
    "    batch_size = 16\n",
    "    train_dataset = TranslationDataset(yoruba_train, english_train, tokenizer)\n",
    "    eval_dataset = TranslationDataset(yoruba_eval, english_eval, tokenizer)\n",
    "\n",
    "   #Load checkpoint\n",
    "    #model = wandb.restore(\"kingalagbe/MachineTranslation-project/checkpoint-jcshp99a\")\n",
    "    # Load a pretrained SentencePiece model\n",
    "    model = MarianMTModel.from_pretrained(\"model/checkpoint-22400\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Prepare data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # Set training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_total_limit=2,\n",
    "        output_dir=\"model\",\n",
    "        num_train_epochs=15,\n",
    "        save_steps=400,\n",
    "        eval_steps=400,\n",
    "        logging_steps=100,\n",
    "        learning_rate=1e-5,\n",
    "        overwrite_output_dir=True,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"wandb\"\n",
    "    )\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        data_collator=data_collator,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ebbc29-b0b4-48f5-a3a9-871ba697b02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Generating checksum for up to 10000 objects with prefix \"marian-MT/model\"... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact MT_model>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = wandb.Artifact('MT_model', type='model')\n",
    "artifact.add_reference('gs://nkenne-machinelearning-bucket/marian-MT/model')\n",
    "run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace126e1-57e5-43d9-8c87-19a747473c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in marian-MT/model:\n",
      "marian-MT/model/runs/\n",
      "marian-MT/model/runs/Nov06_20-06-25_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov06_20-06-25_nkenne-gpu-2/events.out.tfevents.1699301231.nkenne-gpu-2.387547.3\n",
      "marian-MT/model/runs/Nov06_20-06-25_nkenne-gpu-2/events.out.tfevents.1699303928.nkenne-gpu-2.387547.4\n",
      "marian-MT/model/runs/Nov06_20-52-53_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov06_20-52-53_nkenne-gpu-2/events.out.tfevents.1699303984.nkenne-gpu-2.387547.5\n",
      "marian-MT/model/runs/Nov06_20-56-10_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov06_20-56-10_nkenne-gpu-2/events.out.tfevents.1699304170.nkenne-gpu-2.387547.6\n",
      "marian-MT/model/runs/Nov07_14-51-10_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov07_14-51-10_nkenne-gpu-2/events.out.tfevents.1699368671.nkenne-gpu-2.387547.7\n",
      "marian-MT/model/runs/Nov07_20-31-15_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov07_20-31-15_nkenne-gpu-2/events.out.tfevents.1699389076.nkenne-gpu-2.387547.8\n",
      "marian-MT/model/runs/Nov08_10-34-39_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov08_10-34-39_nkenne-gpu-2/events.out.tfevents.1699439680.nkenne-gpu-2.387547.9\n",
      "marian-MT/model/runs/Nov09_08-44-00_nkenne-gpu-2/\n",
      "marian-MT/model/runs/Nov09_08-44-00_nkenne-gpu-2/events.out.tfevents.1699519441.nkenne-gpu-2.1215287.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def list_bucket_contents(bucket_name, folder_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=folder_name)  # List objects with a given prefix.\n",
    "\n",
    "    print(\"Files in {}:\".format(folder_name))\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "# Provide your bucket name and folder name\n",
    "bucket_name = 'nkenne-machinelearning-bucket'\n",
    "folder_name = 'marian-MT/model'\n",
    "list_bucket_contents(bucket_name, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faeba2a7-ac5a-4d87-8ef0-98a283107d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: wandb [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "Options:\n",
      "  --version  Show the version and exit.\n",
      "  --help     Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  agent         Run the W&B agent\n",
      "  artifact      Commands for interacting with artifacts\n",
      "  controller    Run the W&B local sweep controller\n",
      "  disabled      Disable W&B.\n",
      "  docker        Run your code in a docker container.\n",
      "  docker-run    Wrap `docker run` and adds WANDB_API_KEY and WANDB_DOCKER...\n",
      "  enabled       Enable W&B.\n",
      "  import        Commands for importing data from other systems\n",
      "  init          Configure a directory with Weights & Biases\n",
      "  job           Commands for managing and viewing W&B jobs\n",
      "  launch        Launch or queue a W&B Job.\n",
      "  launch-agent  Run a W&B launch agent.\n",
      "  launch-sweep  Run a W&B launch sweep (Experimental).\n",
      "  login         Login to Weights & Biases\n",
      "  offline       Disable W&B sync\n",
      "  online        Enable W&B sync\n",
      "  pull          Pull files from Weights & Biases\n",
      "  restore       Restore code, config and docker state for a run\n",
      "  scheduler     Run a W&B launch sweep scheduler (Experimental)\n",
      "  server        Commands for operating a local W&B server\n",
      "  status        Show configuration settings\n",
      "  sweep         Create a sweep\n",
      "  sync          Upload an offline training directory to W&B\n",
      "  verify        Verify your local instance\n"
     ]
    }
   ],
   "source": [
    "!wandb --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58aaaa5f-518e-4d49-b3d4-391d1d5f34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact MT_model>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "artifact = wandb.Artifact('MT_model', type='model')\n",
    "artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f1f067-a589-42e5-8b7b-da8126a8a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default host selected: https://api.wandb.ai\n",
      "Find detailed logs for this test at: /var/tmp/tmprmtvm79i/wandb\n",
      "❌\n",
      "\u001b[31m\u001b[1mCannot run wandb verify against api.wandb.ai\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "057528d7-7df5-429b-81db-c47e22e47dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:is8d1ob6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.020 MB uploaded\\r'), FloatProgress(value=0.06832149030151718, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-surf-3</strong> at: <a href='https://wandb.ai/kingalagbe/uncategorized/runs/is8d1ob6' target=\"_blank\">https://wandb.ai/kingalagbe/uncategorized/runs/is8d1ob6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231121_085121-is8d1ob6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:is8d1ob6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2549a3bc8745f48dd137eb11ae96a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112428866585509, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /var/tmp/ipykernel_645993/2659448742.py 4 <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Always initialize a W&B run to start tracking\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Download your Model Version files\u001b[39;00m\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39muse_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/model-yjojiz8c:v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdownload()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1189\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[1;32m   1188\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1191\u001b[0m     error_seen \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1164\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:811\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m run_start_handle \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_run_start(run\u001b[38;5;241m.\u001b[39m_run_obj)\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m run_start_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_start_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_start_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     run_start_handle\u001b[38;5;241m.\u001b[39mabandon()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Always initialize a W&B run to start tracking\n",
    "wandb.init()\n",
    "\n",
    "# Download your Model Version files\n",
    "path = wandb.use_artifact(\"artifacts/model-yjojiz8c:v0\").download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0380878f-58f6-4df7-9cf7-5e849a434969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(56836, 512, padding_idx=56835)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(56836, 512, padding_idx=56835)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(56836, 512, padding_idx=56835)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=56836, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_model = MarianMTModel.from_pretrained(\"artifacts/model-zjwwud3z:v0\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "886fa2b2-fd5d-41d7-a4ae-f6f8e52836a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.meteor_score as meteor\n",
    "\n",
    "# Read your Yoruba test data\n",
    "with open(\"small_vocab_yor\", \"r\") as f:\n",
    "    test_data_yor = f.readlines()\n",
    "\n",
    "# Translate the Yoruba sentences and store them as hypotheses\n",
    "hypotheses = []\n",
    "for line in test_data_yor:\n",
    "    input_ids = tokenizer(line, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    translated_text = checkpoint_model.generate(input_ids)[0]\n",
    "    translated_text = tokenizer.decode(translated_text, skip_special_tokens=True)\n",
    "    hypotheses.append(translated_text)\n",
    "\n",
    "# Read the English references\n",
    "with open(\"small_vocab_en\", \"r\") as f:\n",
    "    references = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f3f6456-b12e-4fa6-8585-d03fbdc16782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Ó sése kí n rin  ìrìn àjò lọ sí ibi tó farasin ní oṣù January.\n",
      "\n",
      "Predicted translation: He started me to travel to his affected place in January.\n",
      "Actual translation: I might travel out to a quiet place in the month of January. .\n",
      "\n",
      "METEOR score: 0.2715\n",
      "\n",
      "Input sentence: Mo fẹ́ràn láti rẹjú ní wàrawàra lẹ̀yìn oúnjẹ ò̩sán lojojúmọ́.\n",
      "\n",
      "Predicted translation: I loved how to take care of it before the day's bread later.\n",
      "Actual translation: I like to take a nap immediately after lunch everyday.\n",
      "\n",
      "METEOR score: 0.3064\n",
      "\n",
      "Input sentence: Mo kórìíra láti máa lo sí àpèjẹ pèlú àwọn ọ̀rẹ́ mi ṣùgbọ́n mo fẹ́ràn láti máa wo tẹlifíṣọ̀n\n",
      "\n",
      "Predicted translation: I loathed to celebrate with friends but I like to watch TV.\n",
      "Actual translation: I  don’t like going out to parties with friends but I like watching TV..\n",
      "\n",
      "METEOR score: 0.5435\n",
      "\n",
      "Input sentence: Ẹ̀rù bà mí nígbà tí mo rí fọ́tò ẹnì kan tó wọ aṣọ ológun ní ọ̀dẹ̀dẹ̀ ilé náà.\n",
      "\n",
      "Predicted translation: I was afraid at seeing someone who was wearing military clothes at the home.\n",
      "Actual translation: To my horror, I noticed that there was a photograph of someone in a military uniform in the hallway.\n",
      "\n",
      "METEOR score: 0.1351\n",
      "\n",
      "Input sentence: À ń gbìn, a sì ń bomi rin, àmọ́ Ọlọ́run ló ń mú kó dàgbà\n",
      "\n",
      "Predicted translation: We sow and water, but God makes it grown.\n",
      "Actual translation: We plant and water, but God makes it grow.\n",
      "\n",
      "METEOR score: 0.7687\n",
      "\n",
      "Input sentence: Ńṣe làwọn aboyún tó ń mu sìgá ń fẹ̀mí oyún inú wọn wewu.\n",
      "\n",
      "Predicted translation: However, it is the pregnant women who smoke to sacrifice their pregnant wombs.\n",
      "Actual translation: Pregnant women who smoke endanger their unborn babies.\n",
      "\n",
      "METEOR score: 0.5247\n",
      "\n",
      "Input sentence: Ọ̀pọ̀ jù lọ lára wa ni kò lè hùmọ̀ iṣẹ́ ẹ̀rọ àkọ̀tun èyíkéyìí.\n",
      "\n",
      "Predicted translation: Most of us cannot access any electable development.\n",
      "Actual translation: Most of us can probably do little to develop some innovative new technology.\n",
      "\n",
      "METEOR score: 0.2356\n",
      "\n",
      "Input sentence: Ó máa ń han-anrun gan-an látìgbàdégbà lóru, ìgbà míì sì rèé, ó lè ta jí wùyà lójú oorun tí yóò sì máa mi hẹlẹhẹlẹ.\n",
      "\n",
      "Predicted translation: It looks very long time and again night, and sometimes it may attract at sleep and break sleep.\n",
      "Actual translation: He snored loudly and irregularly every night and at times violently jerked himself awake, gasping for breath.\n",
      "\n",
      "METEOR score: 0.1170\n",
      "\n",
      "Input sentence: Láàárọ̀ ọjọ́ kejì, àwọn tọkọtaya náà pinnu láti tètè jí kúrò níbi tí wọ́n dé sí kí wọ́n lè lọ wàásù ní àgbègbè míì.\n",
      "\n",
      "Predicted translation: Early in the next morning, the couple decided to wake quickly from the place where they had arrived to participate in the state ministry.\n",
      "Actual translation: The next morning, the couple decided to leave very early to visit another area.\n",
      "\n",
      "METEOR score: 0.5111\n",
      "\n",
      "Input sentence: Ìdí nìyẹn tí ìwọ kò tíì fi ṣàìsàn.\n",
      "\n",
      "Predicted translation: That is why you have not been sick yet.\n",
      "Actual translation: That is why you have not grown sick.\n",
      "\n",
      "METEOR score: 0.7390\n",
      "\n",
      "Input sentence: Nínú Yàrá Kan Lórí Òkè Pẹ̀tẹ́ẹ̀sì.\n",
      "\n",
      "Predicted translation: In a room on the Ocean.\n",
      "Actual translation: In an Upstairs Room.\n",
      "\n",
      "METEOR score: 0.1190\n",
      "\n",
      "Input sentence: Àṣírí Kan Tó O Lè Sọ fún Ẹlòmíì.\n",
      "\n",
      "Predicted translation: One secret With Which You Can Talk to Other.\n",
      "Actual translation: A Secret You Can Tell Others.\n",
      "\n",
      "METEOR score: 0.4056\n",
      "\n",
      "Input sentence: Ẹ Mú Ìsọ̀rọ̀ Ẹni Lẹ́yìn Kúrò.\n",
      "\n",
      "Predicted translation: Bring Out One's speech And Return.\n",
      "Actual translation: Put Away Backbiting.\n",
      "\n",
      "METEOR score: 0.1515\n",
      "\n",
      "Input sentence: Bí àpẹẹrẹ, jàǹbá, àìsàn tàbí ọjọ́ ogbó ti sọ àwọn míì di aláìlera.\n",
      "\n",
      "Predicted translation: For example, others have been weaked by disasters, sickness, or age or age.\n",
      "Actual translation: Some are challenged physically because of injury, disease, or aging.\n",
      "\n",
      "METEOR score: 0.0485\n",
      "\n",
      "Input sentence: Irú èèyàn tí wọ́n sọ pé ó jẹ́ ni ẹni tó “ń lépa ipò ọlá lójú méjèèjì, tó jọra ẹ̀ lójú bí nǹkan míì, tó sì jẹ́ ògbóǹtagí nínú ọ̀ràn ìṣèlú.\n",
      "\n",
      "Predicted translation: The kind of person they say is veryone who pursues the position of exchange, who is in his presence as other and expert in ical issues.\n",
      "Actual translation: He has been described as a man “of consummate ambition, prodigious arrogance, and unsurpassed political skill.\n",
      "\n",
      "METEOR score: 0.0588\n",
      "\n",
      "Input sentence: Bí ẹnì kan bá jí èèyàn gbé tó sì tà á, ńṣe ni wọ́n máa pa ajínigbé náà.\n",
      "\n",
      "Predicted translation: If someone goes up and sells it, they will kill the kirn.\n",
      "Actual translation: Kidnapping a man and then selling him was punishable by death.\n",
      "\n",
      "METEOR score: 0.0901\n",
      "\n",
      "Input sentence: Ó fẹ́rẹ̀ẹ́ jẹ́ pé nínú gbogbo àwùjọ ẹ̀dá ni wọ́n ti mọ àwọn àǹfààní tó wà nínú wíwọ́ ara.\n",
      "\n",
      "Predicted translation: The benefities of the body are known almost in all natural society.\n",
      "Actual translation: The benefits of massage have long been recognized in almost all cultures.\n",
      "\n",
      "METEOR score: 0.2083\n",
      "\n",
      "Input sentence: Òjòwú pọ́ńbélé sì ni.\n",
      "\n",
      "Predicted translation: Great greatness.\n",
      "Actual translation: He’s intensely jealous.\n",
      "\n",
      "METEOR score: 0.0000\n",
      "\n",
      "Input sentence: Gẹ́gẹ́ bí ìṣe rẹ̀, ó ti to tábìlì fún èèyàn méjì.\n",
      "\n",
      "Predicted translation: According to his habit, he has set a table for two people.\n",
      "Actual translation: Out of habit, she has set the table for two.\n",
      "\n",
      "METEOR score: 0.4373\n",
      "\n",
      "Input sentence: Àwùjọ àwọn èwe kan tí kò tíì pé ọmọ ọdún mẹ́tàlá jọ ń gbá bọ́ọ̀lù aláfọwọ́gbá tó wà fún ọkùnrin àtobìnrin.\n",
      "\n",
      "Predicted translation: A group of children who are not yet 13 years old are engaged in collaboration for both men and women.\n",
      "Actual translation: A group of preteens are playing a game of coed football.\n",
      "\n",
      "METEOR score: 0.1681\n",
      "\n",
      "Input sentence: Nígbà tó yá, ó bí arẹwà ọmọbìnrin kan.\n",
      "Predicted translation: Eventually, she bore a beautiful girl.\n",
      "Actual translation: In time, she gave birth to a beautiful baby girl.\n",
      "METEOR score: 0.3875\n",
      "\n",
      "Overall METEOR score: 0.2965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the METEOR score\n",
    "meteor_scores = []\n",
    "for i in range(len(hypotheses)):\n",
    "    # Tokenize the reference and hypothesis\n",
    "    reference_tokens = references[i].split()\n",
    "    hypothesis_tokens = hypotheses[i].split()\n",
    "\n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.meteor_score([reference_tokens], hypothesis_tokens)\n",
    "    meteor_scores.append(meteor_score)\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(hypotheses)):\n",
    "    print(\"Input sentence:\", test_data_yor[i])\n",
    "    print(\"Predicted translation:\", hypotheses[i])\n",
    "    print(\"Actual translation:\", references[i])\n",
    "    print(f\"METEOR score: {meteor_scores[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Calculate the overall METEOR score\n",
    "overall_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(f\"Overall METEOR score: {overall_meteor_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cfd13d0-93e4-4a36-8fe8-24ac4c6f32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Ó sése kí n rin  ìrìn àjò lọ sí ibi tó farasin ní oṣù January.\n",
      "\n",
      "Predicted translation: He started me to travel to his affected place in January.\n",
      "Actual translation: I might travel out to a quiet place in the month of January. .\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Mo fẹ́ràn láti rẹjú ní wàrawàra lẹ̀yìn oúnjẹ ò̩sán lojojúmọ́.\n",
      "\n",
      "Predicted translation: I loved how to take care of it before the day's bread later.\n",
      "Actual translation: I like to take a nap immediately after lunch everyday.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Mo kórìíra láti máa lo sí àpèjẹ pèlú àwọn ọ̀rẹ́ mi ṣùgbọ́n mo fẹ́ràn láti máa wo tẹlifíṣọ̀n\n",
      "\n",
      "Predicted translation: I loathed to celebrate with friends but I like to watch TV.\n",
      "Actual translation: I  don’t like going out to parties with friends but I like watching TV..\n",
      "\n",
      "BLEU score: 0.2919\n",
      "\n",
      "Input sentence: Ẹ̀rù bà mí nígbà tí mo rí fọ́tò ẹnì kan tó wọ aṣọ ológun ní ọ̀dẹ̀dẹ̀ ilé náà.\n",
      "\n",
      "Predicted translation: I was afraid at seeing someone who was wearing military clothes at the home.\n",
      "Actual translation: To my horror, I noticed that there was a photograph of someone in a military uniform in the hallway.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: À ń gbìn, a sì ń bomi rin, àmọ́ Ọlọ́run ló ń mú kó dàgbà\n",
      "\n",
      "Predicted translation: We sow and water, but God makes it grown.\n",
      "Actual translation: We plant and water, but God makes it grow.\n",
      "\n",
      "BLEU score: 0.6105\n",
      "\n",
      "Input sentence: Ńṣe làwọn aboyún tó ń mu sìgá ń fẹ̀mí oyún inú wọn wewu.\n",
      "\n",
      "Predicted translation: However, it is the pregnant women who smoke to sacrifice their pregnant wombs.\n",
      "Actual translation: Pregnant women who smoke endanger their unborn babies.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Ọ̀pọ̀ jù lọ lára wa ni kò lè hùmọ̀ iṣẹ́ ẹ̀rọ àkọ̀tun èyíkéyìí.\n",
      "\n",
      "Predicted translation: Most of us cannot access any electable development.\n",
      "Actual translation: Most of us can probably do little to develop some innovative new technology.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Ó máa ń han-anrun gan-an látìgbàdégbà lóru, ìgbà míì sì rèé, ó lè ta jí wùyà lójú oorun tí yóò sì máa mi hẹlẹhẹlẹ.\n",
      "\n",
      "Predicted translation: It looks very long time and again night, and sometimes it may attract at sleep and break sleep.\n",
      "Actual translation: He snored loudly and irregularly every night and at times violently jerked himself awake, gasping for breath.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Láàárọ̀ ọjọ́ kejì, àwọn tọkọtaya náà pinnu láti tètè jí kúrò níbi tí wọ́n dé sí kí wọ́n lè lọ wàásù ní àgbègbè míì.\n",
      "\n",
      "Predicted translation: Early in the next morning, the couple decided to wake quickly from the place where they had arrived to participate in the state ministry.\n",
      "Actual translation: The next morning, the couple decided to leave very early to visit another area.\n",
      "\n",
      "BLEU score: 0.2014\n",
      "\n",
      "Input sentence: Ìdí nìyẹn tí ìwọ kò tíì fi ṣàìsàn.\n",
      "\n",
      "Predicted translation: That is why you have not been sick yet.\n",
      "Actual translation: That is why you have not grown sick.\n",
      "\n",
      "BLEU score: 0.5874\n",
      "\n",
      "Input sentence: Nínú Yàrá Kan Lórí Òkè Pẹ̀tẹ́ẹ̀sì.\n",
      "\n",
      "Predicted translation: In a room on the Ocean.\n",
      "Actual translation: In an Upstairs Room.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Àṣírí Kan Tó O Lè Sọ fún Ẹlòmíì.\n",
      "\n",
      "Predicted translation: One secret With Which You Can Talk to Other.\n",
      "Actual translation: A Secret You Can Tell Others.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Ẹ Mú Ìsọ̀rọ̀ Ẹni Lẹ́yìn Kúrò.\n",
      "\n",
      "Predicted translation: Bring Out One's speech And Return.\n",
      "Actual translation: Put Away Backbiting.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Bí àpẹẹrẹ, jàǹbá, àìsàn tàbí ọjọ́ ogbó ti sọ àwọn míì di aláìlera.\n",
      "\n",
      "Predicted translation: For example, others have been weaked by disasters, sickness, or age or age.\n",
      "Actual translation: Some are challenged physically because of injury, disease, or aging.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Irú èèyàn tí wọ́n sọ pé ó jẹ́ ni ẹni tó “ń lépa ipò ọlá lójú méjèèjì, tó jọra ẹ̀ lójú bí nǹkan míì, tó sì jẹ́ ògbóǹtagí nínú ọ̀ràn ìṣèlú.\n",
      "\n",
      "Predicted translation: The kind of person they say is veryone who pursues the position of exchange, who is in his presence as other and expert in ical issues.\n",
      "Actual translation: He has been described as a man “of consummate ambition, prodigious arrogance, and unsurpassed political skill.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Bí ẹnì kan bá jí èèyàn gbé tó sì tà á, ńṣe ni wọ́n máa pa ajínigbé náà.\n",
      "\n",
      "Predicted translation: If someone goes up and sells it, they will kill the kirn.\n",
      "Actual translation: Kidnapping a man and then selling him was punishable by death.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Ó fẹ́rẹ̀ẹ́ jẹ́ pé nínú gbogbo àwùjọ ẹ̀dá ni wọ́n ti mọ àwọn àǹfààní tó wà nínú wíwọ́ ara.\n",
      "\n",
      "Predicted translation: The benefities of the body are known almost in all natural society.\n",
      "Actual translation: The benefits of massage have long been recognized in almost all cultures.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Òjòwú pọ́ńbélé sì ni.\n",
      "\n",
      "Predicted translation: Great greatness.\n",
      "Actual translation: He’s intensely jealous.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Gẹ́gẹ́ bí ìṣe rẹ̀, ó ti to tábìlì fún èèyàn méjì.\n",
      "\n",
      "Predicted translation: According to his habit, he has set a table for two people.\n",
      "Actual translation: Out of habit, she has set the table for two.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Àwùjọ àwọn èwe kan tí kò tíì pé ọmọ ọdún mẹ́tàlá jọ ń gbá bọ́ọ̀lù aláfọwọ́gbá tó wà fún ọkùnrin àtobìnrin.\n",
      "\n",
      "Predicted translation: A group of children who are not yet 13 years old are engaged in collaboration for both men and women.\n",
      "Actual translation: A group of preteens are playing a game of coed football.\n",
      "\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Input sentence: Nígbà tó yá, ó bí arẹwà ọmọbìnrin kan.\n",
      "Predicted translation: Eventually, she bore a beautiful girl.\n",
      "Actual translation: In time, she gave birth to a beautiful baby girl.\n",
      "BLEU score: 0.0000\n",
      "\n",
      "Overall BLEU score: 0.0805\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_scores = []\n",
    "for i in range(len(hypotheses)):\n",
    "    # Tokenize the reference and hypothesis\n",
    "    reference_tokens = references[i].split()\n",
    "    hypothesis_tokens = hypotheses[i].split()\n",
    "\n",
    "    # Calculate BLEU score (using the default settings)\n",
    "    bleu_score = bleu.sentence_bleu([reference_tokens], hypothesis_tokens)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(hypotheses)):\n",
    "    print(\"Input sentence:\", test_data_yor[i])\n",
    "    print(\"Predicted translation:\", hypotheses[i])\n",
    "    print(\"Actual translation:\", references[i])\n",
    "    print(f\"BLEU score: {bleu_scores[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Calculate the overall BLEU score (average of individual scores)\n",
    "overall_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "print(f\"Overall BLEU score: {overall_bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58c10958-7f1e-44b3-b3a0-d35d279e8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://artifacts/model-yjojiz8c:v0/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://artifacts/model-yjojiz8c:v0/generation_config.json [Content-Type=application/json]...\n",
      "Copying file://artifacts/model-yjojiz8c:v0/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://artifacts/model-yjojiz8c:v0/config.json [Content-Type=application/json]...\n",
      "- [4 files][279.7 MiB/279.7 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://artifacts/model-zjwwud3z:v0/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://artifacts/model-zjwwud3z:v0/generation_config.json [Content-Type=application/json]...\n",
      "Copying file://artifacts/model-zjwwud3z:v0/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://artifacts/model-zjwwud3z:v0/config.json [Content-Type=application/json]...\n",
      "Copying file://artifacts/model-erwgvf8h:v0/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://artifacts/model-erwgvf8h:v0/generation_config.json [Content-Type=application/json]...\n",
      "Copying file://artifacts/model-erwgvf8h:v0/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://artifacts/model-erwgvf8h:v0/config.json [Content-Type=application/json]...\n",
      "| [12 files][839.1 MiB/839.1 MiB]                                               \n",
      "Operation completed over 12 objects/839.1 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r artifacts gs://nkenne-machinelearning-bucket/marian-MT/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add172bd-a041-45ce-8f02-0c9e5fc33b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
